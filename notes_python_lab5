Objective:
1. To build a Machine learning regression model to predict the selling price of the used cars based on the different input features like fuel_type, kms_driven, type of transmission etc.
2. Deploy the machine learning model with the help of the flask framework.

pip install pandas numpy matplotlib seaborn scikit-learn

 **Car_Name**: Name of the car
- **Year**: Year of Purchase
- **Selling Price (target)**: Selling price of the car in lakhs
- **Present Price**: Present price of the car in lakhs
- **Kms_Driven**: kilometers driven
- **Fuel_Type**: Petrol/diesel/CNG
- **Seller_Type**: Dealer or Indiviual
- **Transmission**: Manual or Automatic
- **Owner**: first, second or third owner

Sure, you can modify the code to automatically encode all columns of type 'object'. Here's how you can do it:

```python
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

# Create a dictionary to store the mapping from labels to numbers for each column
label_mapping = {}

# Automatically select columns of type 'object'
columns_to_encode = final_dataset.select_dtypes(include=['object']).columns

for column in columns_to_encode:
    final_dataset[column] = le.fit_transform(final_dataset[column])
    label_mapping[column] = dict(zip(le.classes_, le.transform(le.classes_)))

# Print the label_mapping dictionary
for column, mapping in label_mapping.items():
    print(f'{column}: {mapping}')
```

This code first imports the LabelEncoder class from sklearn.preprocessing. Then it creates a LabelEncoder object and a dictionary to store the mappings. After that, it automatically selects all columns of type 'object' and fits and transforms each of these columns, replacing the original column with the encoded data. It also stores the mapping from labels to numbers for each column in the label_mapping dictionary. Finally, it prints the label_mapping dictionary.

Index(['Selling_Price', 'Present_Price', 'Kms_Driven', 'Fuel_Type',
       'Seller_Type', 'Transmission', 'Owner', 'age_of_the_car'],
      dtype='object')
        
          eg. 0 for CNG, 1 for Diesel & 2 for Petrol
          eg. 0 for Dealer & 1 for Individual
          eg. 0 for Automatic and 1 for Manual

      Fuel_Type: {'CNG': 0, 'Diesel': 1, 'Petrol': 2}
Seller_Type: {'Dealer': 0, 'Individual': 1}
Transmission: {'Automatic': 0, 'Manual': 1}


The r2 score for the training set is very high (0.9856), which indicates that the model fits the training data very well. However, the r2 score for the test set is significantly lower (0.5777), which suggests that the model is not generalizing well to unseen data. This is a classic sign of overfitting.

Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model.

To overcome overfitting, you can try:

1. **Increasing the amount of data**: The more data the model is trained on, the better it will be able to generalize to new data.

2. **Reducing the complexity of the model**: This can be done by tuning hyperparameters. For a Random Forest Regressor, you can try reducing the number of estimators or increasing the minimum number of samples required to split an internal node.

3. **Using regularization techniques**: Regularization adds a penalty on the different parameters of the model to reduce the freedom of the model and in turn, overfitting. In the case of a Random Forest Regressor, this can be done by setting the max_depth parameter.

4. **Using cross-validation**: Cross-validation is a powerful preventative measure against overfitting. The idea is simple: split the training data into a training set and a validation set, train the model on the training set and validate it on the validation set. If the model performs well on the validation set, it's less likely to be overfitting.

Given the situation, I would suggest using cross-validation as it is a powerful preventative measure against overfitting. The idea is simple: split the training data into a training set and a validation set, train the model on the training set and validate it on the validation set. If the model performs well on the validation set, it's less likely to be overfitting.

Here's how you can apply cross-validation using the `cross_val_score` function from sklearn.model_selection:

```python
from sklearn.model_selection import cross_val_score

# Perform cross-validation
scores = cross_val_score(rf, X, y, cv=5)

# Print the scores
print(f'Cross-validation scores: {scores}')

# Print the mean score
print(f'Mean cross-validation score: {scores.mean()}')
```

This code first performs cross-validation on the Random Forest Regressor using the `cross_val_score` function with 5 folds. Then it prints the scores for each fold and the mean score. The mean score gives you an idea of how well the model is likely to perform on unseen data.

Cross-validation scores: [ 0.96420827  0.74293268 -1.66522337  0.95426016  0.77835328]
Mean cross-validation score: 0.35490620138279255
The cross-validation scores show the performance of your model on different subsets of your data. The negative score in the third fold is concerning and indicates that the model performed very poorly on that subset of the data.

The mean cross-validation score is quite low (0.3549), which suggests that the model is not generalizing well to unseen data. This is consistent with the overfitting we suspected earlier.

To improve the model, you could try:

1. **Tuning hyperparameters**: Use GridSearchCV or RandomizedSearchCV from sklearn.model_selection to find the best parameters for your Random Forest Regressor.

2. **Feature selection**: Remove irrelevant input features. They can decrease the accuracy of the model, especially for linear algorithms.

3. **Try different models**: If the Random Forest Regressor is not performing well, you could try other regression models like Linear Regression, Ridge Regression, Lasso Regression, or ElasticNet.

Remember, machine learning involves a lot of experimentation and it's normal to try many different approaches before finding the best one.

Sure, let's try different regression models. We'll use Linear Regression, Ridge Regression, Lasso Regression, and ElasticNet and compare their performances. Here's how you can do it:

```python
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet

# Create a dictionary of different regression models
models = {
    'Linear Regression': LinearRegression(),
    'Ridge Regression': Ridge(),
    'Lasso Regression': Lasso(),
    'ElasticNet': ElasticNet()
}

# Train each model and calculate the cross-validation score
for model_name, model in models.items():
    scores = cross_val_score(model, X, y, cv=5)
    print(f'{model_name} cross-validation scores: {scores}')
    print(f'{model_name} mean cross-validation score: {scores.mean()}')
```

This code first imports the necessary classes from sklearn.linear_model. Then it creates a dictionary of different regression models. After that, it trains each model on the data and calculates the cross-validation score. Finally, it prints the cross-validation scores and the mean cross-validation score for each model.

Linear Regression cross-validation scores: [   0.83936062    0.76650938 -106.57394676    0.60661231    0.83882446]
Linear Regression mean cross-validation score: -20.704527997696054
Ridge Regression cross-validation scores: [   0.8434481     0.76546155 -105.20040206    0.61297351    0.8405628 ]
Ridge Regression mean cross-validation score: -20.427591218305956
Lasso Regression cross-validation scores: [  0.86628922   0.71524629 -98.51069998   0.65265659   0.73811595]
Lasso Regression mean cross-validation score: -19.107678386099302
ElasticNet cross-validation scores: [   0.87019332    0.7238951  -101.80713712    0.69414441    0.76253767]
ElasticNet mean cross-validation score: -19.75127332562447

Sure, we can check for outliers in your data. Outliers are extreme values that deviate from other observations on data, they may indicate a variability in a measurement, experimental errors or a novelty. In other words, an outlier is an observation that diverges from an overall pattern on a sample.

We can use boxplots to visualize the data and identify if there are any outliers. Here's how you can do it:

```python
import matplotlib.pyplot as plt
import seaborn as sns

# List of columns
columns = ['Selling_Price', 'Present_Price', 'Kms_Driven', 'Fuel_Type', 'Seller_Type', 'Transmission', 'Owner', 'age_of_the_car']

# Create a boxplot for each column
for column in columns:
    plt.figure(figsize=(10, 4))
    sns.boxplot(x=final_dataset[column])
    plt.title(f'Boxplot of {column}')
    plt.show()
```

This code first imports the necessary libraries. Then it creates a boxplot for each column in your data. Boxplots are a standardized way of displaying the distribution of data based on a five number summary (“minimum”, first quartile (Q1), median, third quartile (Q3), and “maximum”). It can tell you about your outliers and what their values are. It can also tell you if your data is symmetrical, how tightly your data is grouped, and if and how your data is skewed.

To provide statistical output along with the boxplots, you can use the `describe` method from pandas, which provides descriptive statistics that summarize the central tendency, dispersion, and shape of a dataset’s distribution. Here's how you can do it:

```python
# Create a boxplot and print descriptive statistics for each column
for column in columns:
    plt.figure(figsize=(10, 4))
    sns.boxplot(y=final_dataset[column])
    plt.title(f'Boxplot of {column}')
    plt.show()
    
    # Print descriptive statistics
    print(f'Descriptive statistics for {column}:\n{final_dataset[column].describe()}\n')
```

This code first creates a boxplot for each column in your data. Then it prints the descriptive statistics for each column, which include count, mean, standard deviation, minimum, 25th percentile, median, 75th percentile, and maximum.

Outliers are typically defined as values that are far removed from the median of the data. A common method to identify outliers is to check for values that are outside the range [Q1 - 1.5*IQR, Q3 + 1.5*IQR], where Q1 and Q3 are the first and third quartiles, respectively, and IQR is the interquartile range (Q3 - Q1).

Based on this definition, we can observe potential outliers in the following columns:

1. **Selling_Price**: The maximum value (35.0) is much higher than the 75th percentile (6.0), suggesting it could be an outlier.

2. **Present_Price**: The maximum value (92.6) is much higher than the 75th percentile (9.84), suggesting it could be an outlier.

3. **Kms_Driven**: The maximum value (500000) is much higher than the 75th percentile (48883.5), suggesting it could be an outlier.

4. **Owner**: The maximum value (3) is much higher than the 75th percentile (0), suggesting it could be an outlier.

Please note that these are potential outliers based on a common statistical rule. It's important to consider the context and domain knowledge when deciding whether these values are truly outliers. For example, a very high value for `Kms_Driven` might be expected for certain types of cars or certain use cases.

To treat outliers, one common method is to replace the outlier values with the median of the data. The median is a good choice because it is less sensitive to outliers than the mean. Here's how you can do it:

```python
# List of columns to treat outliers
outlier_columns = ['Selling_Price', 'Present_Price', 'Kms_Driven', 'Owner']

# Treat outliers for each column
for column in outlier_columns:
    # Calculate the IQR of the column
    Q1 = final_dataset[column].quantile(0.25)
    Q3 = final_dataset[column].quantile(0.75)
    IQR = Q3 - Q1

    # Define the upper and lower bounds for outliers
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Identify the outliers
    outliers = final_dataset[(final_dataset[column] < lower_bound) | (final_dataset[column] > upper_bound)]

    # Replace the outliers with the median of the column
    final_dataset[column] = np.where((final_dataset[column] < lower_bound) | (final_dataset[column] > upper_bound), final_dataset[column].median(), final_dataset[column])
```

This code first calculates the interquartile range (IQR) for each column. Then it defines the lower and upper bounds for outliers as [Q1 - 1.5*IQR, Q3 + 1.5*IQR]. It identifies the outliers in the column and replaces them with the median of the column.

Now can I try this? -
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score


# Create a Random Forest Regressor
rf = RandomForestRegressor(n_estimators=100, random_state=42)

# Train the model
rf.fit(X_train, y_train)

# Make predictions on the test set
y_pred = rf.predict(X_test)

# Calculate the r2_score for the train and test sets
r2_train = r2_score(y_train, rf.predict(X_train))
r2_test = r2_score(y_test, y_pred)

print(f'Train r2 score: {r2_train}')
print(f'Test r2 score: {r2_test}')


Yes, you can certainly use the code you've provided to train a Random Forest Regressor and evaluate its performance. However, before you do that, you need to split your data into features (X) and target (y), and then into training and testing sets. Here's how you can do it:

```python
from sklearn.model_selection import train_test_split

# Define the features and the target
X = final_dataset.drop('Selling_Price', axis=1)  # assuming 'Selling_Price' is the target
y = final_dataset['Selling_Price']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Now you can use your code to train the model and make predictions
```

Please replace `'Selling_Price'` with the actual name of your target column if it's different. The `train_test_split` function splits the data into training and testing sets. The `test_size` parameter specifies the proportion of the data to be used as the test set. The `random_state` parameter is used for reproducibility.

Before outliers treatment -
Train r2 score: 0.9856305226349797
Test r2 score: 0.5777259891991424

after outliers treatement -
Train r2 score: 0.9842037174092366
Test r2 score: 0.8832641397712329

The r2 scores you've provided indicate that the model's performance on the test set has significantly improved after outlier treatment. 

Before treating outliers, the model was overfitting the training data, as indicated by a high r2 score on the training set (0.9856) and a much lower r2 score on the test set (0.5777). This suggests that the model was learning the noise in the training data, which was likely due to the outliers.

After treating outliers, the r2 score on the training set slightly decreased (0.9842), but the r2 score on the test set significantly increased (0.8833). This indicates that the model is now generalizing better to unseen data, which is the goal of a good machine learning model.

So, treating outliers in your data has helped to improve the performance of your Random Forest Regressor model.

Now create pkl -
Sure, you can use the `pickle` module in Python to serialize your trained model into a file that can be saved to disk. Here's how you can do it:

```python
import pickle

# Save the trained model as a pickle string.
saved_model = pickle.dumps(rf)

# Save the model to disk
with open('random_forest_model.pkl', 'wb') as file:
    file.write(saved_model)
```

This code first serializes the trained model `rf` into a pickle string, and then writes that string to a file named 'random_forest_model.pkl'. You can load the model later with `pickle.load()`.

Create new folder/new project in visual studio/pycharm that should contain the "model.pkl" file *make sure you are using a virutal environment and install required packages.*
 a) create index.html for which templates folder is available.
 b) Create app.py and write the predict funtion.
 c)  Run app.py to reunder index.html and prediction to happen with the input values please - Index(['Present_Price', 'Kms_Driven', 'Fuel_Type', 'Seller_Type',
       'Transmission', 'Owner', 'age_of_the_car'],
      dtype='object')
Sure, here's a step-by-step guide on how to create a new project with the specified requirements:

1. **Create a new project in Visual Studio Code/PyCharm:**

   Open Visual Studio Code/PyCharm, click on `File -> New Project`, and follow the prompts to create a new project. Make sure to select a virtual environment for the project.

2. **Install the required packages:**

   Open the terminal in your IDE and install the required packages using pip. For this project, you might need packages like Flask, numpy, pandas, and scikit-learn. You can install them with the following commands:

   ```bash
   pip install flask numpy pandas scikit-learn
   ```

3. **Create the necessary files and folders:**

   In your project directory, create the following files and folders:

   - A `templates` folder: This is where Flask looks for HTML templates. Inside this folder, create an `index.html` file.
   - An `app.py` file: This is where you'll write your Flask application.
   - A `model.pkl` file: This is where you'll store your trained model. You can move the `random_forest_model.pkl` file you created earlier to this location and rename it to `model.pkl`.

4. **Write the predict function in `app.py`:**

   Here's a basic example of how you can write a predict function in Flask:

   ```python
   from flask import Flask, request, render_template
   import numpy as np
   import pickle

   app = Flask(__name__)

   # Load the model
   model = pickle.load(open('model.pkl', 'rb'))

   @app.route('/')
   def home():
       return render_template('index.html')

   @app.route('/predict', methods=['POST'])
   def predict():
       # Get the data from the POST request.
       data = request.get_json(force=True)

       # Make prediction using the model loaded from disk as per the data.
       prediction = model.predict([np.array(list(data.values()))])

       # Take the first value of prediction
       output = prediction[0]

       return str(output)

   if __name__ == '__main__':
       app.run(port=5000, debug=True)
   ```

5. **Run `app.py`:**

   You can run `app.py` from the terminal with the following command:

   ```bash
   python app.py
   ```

   This will start a Flask server on your local machine. You can access it by going to `http://localhost:5000` in your web browser.

Please note that this is a basic example and might need to be adjusted based on your specific requirements and data.

Sure, you can create an `index.html` file in the `templates` folder with form fields for each of the features you mentioned. Here's a basic example:

```html
<!DOCTYPE html>
<html>
<head>
    <title>Car Price Prediction</title>
</head>
<body>
    <h1>Car Price Prediction</h1>
    <form action="/predict" method="post">
        <label for="present_price">Present Price:</label><br>
        <input type="text" id="present_price" name="present_price"><br>
        <label for="kms_driven">Kms Driven:</label><br>
        <input type="text" id="kms_driven" name="kms_driven"><br>
        <label for="fuel_type">Fuel Type:</label><br>
        <input type="text" id="fuel_type" name="fuel_type"><br>
        <label for="seller_type">Seller Type:</label><br>
        <input type="text" id="seller_type" name="seller_type"><br>
        <label for="transmission">Transmission:</label><br>
        <input type="text" id="transmission" name="transmission"><br>
        <label for="owner">Owner:</label><br>
        <input type="text" id="owner" name="owner"><br>
        <label for="age_of_the_car">Age of the Car:</label><br>
        <input type="text" id="age_of_the_car" name="age_of_the_car"><br>
        <input type="submit" value="Predict">
    </form>
</body>
</html>
```

This HTML file creates a form with text input fields for each of the features. When the form is submitted, a POST request is made to the `/predict` endpoint with the form data. Please note that this is a basic example and might need to be adjusted based on your specific requirements and data.

To display the prediction result in the `index.html` page, you can modify the `predict` function to render a template with the prediction result. You also need to modify the `index.html` file to display the result. 

Here's how you can modify the `predict` function:

```python
@app.route("/predict", methods=["POST"])
def predict():
    # Get the data from the POST request.
    data = request.form

    # Make prediction using the model loaded from disk as per the data.
    prediction = model.predict([np.array(list(map(float, data.values())))])

    # Take the first value of prediction
    output = prediction[0]

    # Print the output to the console
    print('Prediction: ', output)

    # Render the index.html template with the prediction result
    return render_template("index.html", prediction_text='Predicted Price should be {}'.format(output))
```

And here's how you can modify the `index.html` file to display the prediction result:

```html
<!DOCTYPE html>
<html>
<head>
    <title>Car Price Prediction</title>
</head>
<body>
    <h1>Car Price Prediction</h1>
    <form action="/predict" method="post">
        <!-- form fields go here -->
        <input type="submit" value="Predict">
    </form>
    {% if prediction_text %}
    <h2>{{ prediction_text }}</h2>
    {% endif %}
</body>
</html>
```

In the `predict` function, `request.form` is used instead of `request.get_json(force=True)` to get the form data. The `map` function is used to convert the form data to float before making the prediction. The prediction result is printed to the console and passed to the `render_template` function to be displayed in the `index.html` page.

In the `index.html` file, the `{% if prediction_text %}` statement checks if the `prediction_text` variable is defined, and if it is, it displays its value in a `<h2>` element. The `{{ prediction_text }}` syntax is used to insert the value of the `prediction_text` variable into the HTML.

If you want to add logging to your Flask application, you can use the `logging` module in Python. Here's how you can do it:

First, import the `logging` module at the top of your `app.py` file:

```python
import logging
```

Then, configure the logging module to log messages to a file with a certain severity level. You can do this before the `if __name__ == "__main__":` line:

```python
logging.basicConfig(filename='app.log', level=logging.INFO)
```

Now, you can use `logging.info()` to log informational messages. Replace the `print()` statement in the `predict` function with `logging.info()`:

```python
logging.info("Prediction: %s", output)
```

Here's the updated `app.py` file:

```python
from flask import Flask, request, render_template
import numpy as np
import pickle
import logging

app = Flask(__name__)

# Load the model
model = pickle.load(open("model.pkl", "rb"))

@app.route("/")
def home():
    return render_template("index.html")

@app.route("/predict", methods=["POST"])
def predict():
    # Get the data from the POST request.
    data = request.form

    # Make prediction using the model loaded from disk as per the data.
    prediction = model.predict([np.array(list(map(float, data.values())))])

    # Take the first value of prediction
    output = prediction[0]

    # Log the output
    logging.info("Prediction: %s", output)

    # Render the index.html template with the prediction result
    return render_template(
        "index.html", prediction_text="Predicted Price should be {}".format(output)
    )

if __name__ == "__main__":
    logging.basicConfig(filename='app.log', level=logging.INFO)
    app.run(port=5000, debug=True)
```

Now, all log messages with a severity level of INFO or higher will be written to a file named `app.log`.

The fields in the HTML form are matched in the `app.py` Flask application through the `request.form` object. When the form is submitted, a POST request is sent to the `/predict` route in the Flask application. The data from the form fields is included in this request as form data.

In the `/predict` route, `data = request.form` is used to get the form data. `request.form` is a special type of dict in Flask that contains all the form fields as key-value pairs. The keys are the `name` attributes of the form fields, and the values are the data entered by the user.

The line `prediction = model.predict([np.array(list(map(float, data.values())))])` is used to make a prediction with the model. `data.values()` gets all the values from the form data, `map(float, data.values())` converts these values to floats, and `list(map(float, data.values()))` converts this to a list. This list is then converted to a numpy array and passed to `model.predict()` to make a prediction.

The predicted value is then passed to the `render_template` function as `prediction_text`, which is used in the HTML to display the prediction result to the user. The `{% if prediction_text %}` block in the HTML is a Jinja2 template conditional that checks if `prediction_text` is not None or empty. If `prediction_text` is not None or empty, the prediction result is displayed in a div.

Yes, the order of the fields in the HTML form does not matter when fetching the data in Flask. The `request.form` object in Flask is a type of dictionary where each key-value pair corresponds to a form field and its value. 

When you submit the form, the browser sends a POST request to the server with the form data. The form data is included in the request body, and each key-value pair in the form data corresponds to a form field name (the key) and its value.

In your Flask app, when you do `data = request.form`, you're getting this form data as a dictionary. The order of the fields in the dictionary does not necessarily match the order of the fields in the form. 

So, even if you change the order of the fields in the HTML form, as long as the field names (`name` attribute in the HTML form) match the keys you're using to access the data in your Flask app, you'll still get the correct data.


<!DOCTYPE html>
<html>

<head>
    <title>Car Price Prediction</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <style>
        body {
            background: url('/static/Background.jpg') no-repeat center center fixed; 
            -webkit-background-size: cover;
            -moz-background-size: cover;
            -o-background-size: cover;
            background-size: cover;
        }
        .container {
            max-height: 80vh;
            overflow-y: auto;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1 class="my-4">
            <img src="/static/logo.jpg" alt="Logo"> Car Price Prediction
        </h1>
        <!-- Rest of your form -->
    </div>
</body>

</html>


To flash a message at the center of the form, you can use Flask's `flash` function to send a message to the next request, which you can then display in your HTML. Here's how you can modify your Python code and HTML:

In your Python code, import the `flash` function and use it to send a message:

```python
from flask import Flask, request, render_template, flash

# ...

@app.route("/predict", methods=["POST"])
def predict():
    # ...
    flash("Predicted resale Price is {}".format(output))
    return render_template("index.html")
```

In your HTML, use the `get_flashed_messages` function to get and display the messages:

```html
<div class="container">
    <!-- ... -->
    {% with messages = get_flashed_messages() %}
    {% if messages %}
    <div class="alert alert-info text-center">
        {% for message in messages %}
        <h2>{{ message }}</h2>
        {% endfor %}
    </div>
    {% endif %}
    {% endwith %}
    <!-- ... -->
</div>
```

The `get_flashed_messages` function gets all the messages that were flashed. The `{% with %}` statement is used to assign the messages to a variable. The `{% if %}` statement checks if there are any messages, and if there are, it displays each one in a `<h2>` element inside a Bootstrap alert. The `text-center` class is used to center the text.